from collections import Counter
import re

def get_2grams(text):
    # Define stop words
    stop_words = set(["of", "to", "a", "the", "and", "in", "for", "who","such","an","with","will","an","this","is","some","such","are","but","on","as", "s","or"])

    # Tokenize the text into words
    words = re.findall(r'\b\w+\b', text.lower())

    # Remove stop words
    filtered_words = [word for word in words if word not in stop_words]

    # Generate 2-grams
    ngrams = zip(filtered_words, filtered_words[1:])

    return ngrams

def analyze_2grams(text):
    # Get 2-grams
    ngrams = get_2grams(text)

    # Count the occurrences of each 2-gram
    ngram_counts = Counter(ngrams)

    # Sort by frequency
    sorted_ngrams = sorted(ngram_counts.items(), key=lambda x: x[1], reverse=True)

    return sorted_ngrams

def display_top_ngrams(sorted_ngrams, n=10):
    print("Top", n, "2-grams:")
    for ngram, count in sorted_ngrams[:n]:
        print(' '.join(ngram), "-", count)

# Provided text
provided_text = input("What job description do you want to parse?")

# Analyze and display top 2-grams
sorted_ngrams = analyze_2grams(provided_text)
print("\n")
display_top_ngrams(sorted_ngrams)
